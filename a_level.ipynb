{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145577ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4ab47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLIP before importing other libraries to avoid memory issues\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a1eb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aneeshponduru/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aneeshponduru/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5dbe469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and preprocess\n",
    "df_raw = pd.read_parquet(\"train-00000-of-00001-60e50ff5fbbd1bb5.parquet\")\n",
    "df_unique = df_raw.drop_duplicates(subset=[\"video_id\"]).copy()\n",
    "df_unique[\"image_path\"] = df_unique[\"video_id\"].apply(lambda vid: f\"images/{vid}.jpg\")\n",
    "df_unique = df_unique[df_unique[\"image_path\"].apply(lambda p: Path(p).exists())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5c111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize image embeddings and valid video IDs\n",
    "clip_embeddings = []\n",
    "valid_video_ids = []\n",
    "\n",
    "# for each image, preprocess and encode\n",
    "for _, row in df_unique.iterrows():\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        image = preprocess(Image.open(row[\"image_path\"])).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            # Encode the image\n",
    "            embedding = model.encode_image(image).cpu().numpy()[0]\n",
    "\n",
    "        # Store the embedding and video ID\n",
    "        clip_embeddings.append(embedding)\n",
    "        valid_video_ids.append(row[\"video_id\"])\n",
    "\n",
    "        # Clear memory\n",
    "        del image\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception as e:\n",
    "        # Handle errors by skipping the video\n",
    "        print(f\"Skipping {row['video_id']}: {e}\")\n",
    "\n",
    "# Create DataFrame for valid videos\n",
    "clip_embeddings = np.array(clip_embeddings)\n",
    "df_clip = df_unique[df_unique[\"video_id\"].isin(valid_video_ids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2933ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build FAISS index and normalize embeddings\n",
    "clip_embeddings = clip_embeddings / np.linalg.norm(clip_embeddings, axis=1, keepdims=True)\n",
    "index = faiss.IndexFlatIP(clip_embeddings.shape[1])\n",
    "index.add(clip_embeddings)\n",
    "\n",
    "# Use captions to create BM25 index\n",
    "df_clip[\"tokens\"] = df_clip[\"caption\"].fillna(\"\").apply(\n",
    "    lambda x: [word for word in word_tokenize(x.lower()) if word.isalnum() and word not in stop_words]\n",
    ")\n",
    "\n",
    "# Initialize BM25 with tokenized captions\n",
    "bm25 = BM25Okapi(df_clip[\"tokens\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9794e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define queries\n",
    "queries = [\n",
    "    \"a snowy mountain with a clear blue sky\",\n",
    "    \"a crowded city street at night with neon signs\",\n",
    "    \"a peaceful beach with palm trees and waves crashing\",\n",
    "    \"a person jogging through a park in the morning\",\n",
    "    \"a chef chopping vegetables in a kitchen\",\n",
    "    \"a surfer riding a big wave\",\n",
    "    \"a red sports car in front of a building\",\n",
    "    \"a golden retriever sitting on a grassy field\",\n",
    "    \"a firefighter rescuing a person from a burning building at night\",\n",
    "    \"a person near luxury cars in cloudy weather speaking to someone\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe156c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode queries with CLIP\n",
    "with torch.no_grad():\n",
    "    text_tokens = clip.tokenize(queries).to(device)\n",
    "    query_clip_embs = model.encode_text(text_tokens).cpu().numpy()\n",
    "\n",
    "# Use queries to get BM25 scores\n",
    "query_bm25_tokens = [word_tokenize(q.lower()) for q in queries]\n",
    "bm25_scores_all = [bm25.get_scores(tokens) for tokens in query_bm25_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5712f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list for results\n",
    "results = []\n",
    "\n",
    "# for each query, compute scores and rank\n",
    "for i, query in enumerate(queries):\n",
    "    # Get the query embedding\n",
    "    query_emb = query_clip_embs[i]\n",
    "\n",
    "    # Normalize the query embedding\n",
    "    query_emb = query_emb / np.linalg.norm(query_emb)\n",
    "\n",
    "    # Reshape to 2D for FAISS\n",
    "    query_emb_2d = np.expand_dims(query_emb, axis=0)\n",
    "\n",
    "    # FAISS cosine-like search\n",
    "    faiss_scores_all, _ = index.search(query_emb_2d, len(df_clip))\n",
    "    clip_scores = faiss_scores_all[0]\n",
    "\n",
    "    # BM25 scoring\n",
    "    bm25_scores = np.array(bm25_scores_all[i])\n",
    "    norm_bm25 = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores))\n",
    "\n",
    "    # Hybrid scoring\n",
    "    hybrid_scores = 0.7 * clip_scores + 0.3 * norm_bm25\n",
    "    top_indices = np.argsort(hybrid_scores)[::-1][:5]\n",
    "\n",
    "    for rank, idx in enumerate(top_indices):\n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"rank\": rank + 1,\n",
    "            \"video_id\": df_clip.iloc[idx][\"video_id\"],\n",
    "            \"caption\": df_clip.iloc[idx][\"caption\"],\n",
    "            \"url\": df_clip.iloc[idx][\"url\"],\n",
    "            \"start time\": df_clip.iloc[idx][\"start time\"],\n",
    "            \"end time\": df_clip.iloc[idx][\"end time\"],\n",
    "            \"clip_similarity\": clip_scores[idx],\n",
    "            \"bm25_score\": bm25_scores[idx],\n",
    "            \"normalized bm25\": norm_bm25[idx],\n",
    "            \"hybrid_score\": hybrid_scores[idx]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca8c7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to a_grade_hybrid_results-2.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results as a DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Use query list to get the same query order as the list of queries\n",
    "query_order = {q: i for i, q in enumerate(queries)}\n",
    "df_results[\"query_order\"] = df_results[\"query\"].map(query_order)\n",
    "\n",
    "# Sort by custom order, then hybrid score\n",
    "df_results = df_results.sort_values([\"query_order\", \"hybrid_score\"], ascending=[True, False])\n",
    "df_results = df_results.drop(columns=[\"query_order\"])\n",
    "\n",
    "# Save to CSV for manual annotation\n",
    "df_results = pd.DataFrame(results)\n",
    "if not os.path.exists(\"a_grade_hybrid_results.csv\"):\n",
    "    df_results.to_csv(\"a_grade_hybrid_results.csv\", index=False)\n",
    "    print(\"Results saved to a_grade_hybrid_results.csv\")\n",
    "else:\n",
    "    print(\"File already exists. No save performed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4868d0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5 per query:\n",
      "- a chef chopping vegetables in a kitchen...: 0.891\n",
      "- a crowded city street at night with neon signs...: 0.968\n",
      "- a firefighter rescuing a person from a burning bui...: 1.000\n",
      "- a golden retriever sitting on a grassy field...: 0.624\n",
      "- a peaceful beach with palm trees and waves crashin...: 0.967\n",
      "- a person jogging through a park in the morning...: 0.631\n",
      "- a person near luxury cars in cloudy weather speaki...: 1.000\n",
      "- a red sports car in front of a building...: 0.567\n",
      "- a snowy mountain with a clear blue sky...: 0.969\n",
      "- a surfer riding a big wave...: 0.000\n",
      "\n",
      "Mean NDCG@5 across all queries: 0.762\n"
     ]
    }
   ],
   "source": [
    "# Reload the results after manual annotation\n",
    "df = pd.read_csv(\"a_grade_hybrid_results.csv\")\n",
    "\n",
    "# Convert the relevance column to numeric, handling errors and filling NaN with 0\n",
    "df[\"relevance\"] = pd.to_numeric(df[\"relevance\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# Function to calculate DCG\n",
    "def dcg(scores):\n",
    "    return sum(score / np.log2(idx + 2) for idx, score in enumerate(scores))\n",
    "\n",
    "# Dictionary to store NDCG scores\n",
    "ndcg_scores = {}\n",
    "\n",
    "# Calculate NDCG for each query\n",
    "for query, group in df.groupby(\"query\"):\n",
    "    # Sort by predicted rank \n",
    "    top_k = group.sort_values(\"rank\").head(5)\n",
    "    \n",
    "    # Calculate DCG for the ranking\n",
    "    relevance = top_k[\"relevance\"].tolist()\n",
    "    actual_dcg = dcg(relevance)\n",
    "    \n",
    "    # Ideal DCG (perfect ranking of same scores)\n",
    "    ideal_relevance = sorted(relevance, reverse=True)\n",
    "    ideal_dcg = dcg(ideal_relevance)\n",
    "    \n",
    "    # Calculate NDCG\n",
    "    ndcg = actual_dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "    ndcg_scores[query] = ndcg\n",
    "\n",
    "# Print per-query and average NDCG@5\n",
    "print(\"NDCG@5 per query:\")\n",
    "for query, score in ndcg_scores.items():\n",
    "    print(f\"- {query[:50]}...: {score:.3f}\")\n",
    "\n",
    "mean_ndcg = np.mean(list(ndcg_scores.values()))\n",
    "print(f\"\\nMean NDCG@5 across all queries: {mean_ndcg:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
