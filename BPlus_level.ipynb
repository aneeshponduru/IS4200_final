{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check if a video exists on YouTube\n",
    "# exists if the video is available and not private\n",
    "def video_exists_youtube(url):\n",
    "    try:\n",
    "        # Headers to mimic a browser request\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "        }\n",
    "        # Get the video page\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        time.sleep(1)  # Be polite to the server\n",
    "\n",
    "        # Check if the response is successful\n",
    "        if response.status_code != 200:\n",
    "            return False\n",
    "\n",
    "        # Get the HTML content and intialize unavailable phrases\n",
    "        html = response.text.lower()\n",
    "        unavailable_phrases = [\n",
    "            \"video is not available\",\n",
    "            \"video unavailable\",\n",
    "            \"this video is private\",\n",
    "            \"this video has been removed\",\n",
    "            \"this video is no longer available\"\n",
    "        ]\n",
    "\n",
    "        # Check if any of the unavailable phrases are in the HTML\n",
    "        for phrase in unavailable_phrases:\n",
    "            if phrase in html:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    # exception handling for request failures\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking video {url}: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for the 100 sampled videos\n",
    "df_unique = pd.read_csv(\"sampled_data_100_videos.csv\")\n",
    "\n",
    "# Add image path for each video\n",
    "df_unique[\"image_path\"] = df_unique[\"video_id\"].apply(lambda vid: f\"images/{vid}.jpg\")\n",
    "\n",
    "# Filter out rows where the image file does not exist\n",
    "df_unique = df_unique[df_unique[\"image_path\"].apply(lambda p: Path(p).exists())].reset_index(drop=True)\n",
    "\n",
    "# Load CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Initialize lists to store image embeddings and valid video IDs\n",
    "image_embeddings = []\n",
    "valid_video_ids = []\n",
    "\n",
    "# For each image, preprocess and encode it\n",
    "for _, row in df_unique.iterrows():\n",
    "    try:\n",
    "        # Use CLIP to preprocess and encode the image\n",
    "        image = preprocess(Image.open(row[\"image_path\"])).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            image_embedding = model.encode_image(image).cpu().numpy()[0]\n",
    "        \n",
    "        # Add the image embedding and video_id to the respective list\n",
    "        image_embeddings.append(image_embedding)\n",
    "        valid_video_ids.append(row[\"video_id\"])\n",
    "    # handle exceptions\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {row['video_id']}: {e}\")\n",
    "\n",
    "# Restrict to only those that succeeded\n",
    "df_clip = df_unique[df_unique[\"video_id\"].isin(valid_video_ids)].reset_index(drop=True)\n",
    "image_embeddings = np.array(image_embeddings)\n",
    "\n",
    "# Initialize a list of queries\n",
    "queries = [\n",
    "    \"a snowy mountain with a clear blue sky\",\n",
    "    \"a crowded city street at night with neon signs\",\n",
    "    \"a peaceful beach with palm trees and waves crashing\",\n",
    "    \"a person jogging through a park in the morning\",\n",
    "    \"a chef chopping vegetables in a kitchen\",\n",
    "    \"a surfer riding a big wave\",\n",
    "    \"a red sports car in front of a building\",\n",
    "    \"a golden retriever sitting on a grassy field\",\n",
    "    \"a firefighter rescuing a person from a burning building at night\",\n",
    "    \"a person near luxury cars in cloudy weather speaking to someone\"\n",
    "]\n",
    "\n",
    "# Encode the text queries using CLIP text encoder\n",
    "with torch.no_grad():\n",
    "    text_tokens = clip.tokenize(queries).to(device)\n",
    "    text_embeddings = model.encode_text(text_tokens).cpu().numpy()\n",
    "\n",
    "# Compute cosine similarity between each query and all video frames\n",
    "similarities = cosine_similarity(text_embeddings, image_embeddings)\n",
    "\n",
    "# Set a threshold for similarity\n",
    "threshold = 0.15\n",
    "results = []\n",
    "\n",
    "# for each query, find the top 5 most similar video frames\n",
    "for i, query in enumerate(queries):\n",
    "    # Get the similarity scores for the current query\n",
    "    sim_scores = similarities[i]\n",
    "    \n",
    "    # Store the similarity scores in the dataframe\n",
    "    df_clip[\"similarity\"] = sim_scores\n",
    "\n",
    "    # Filter out rows with similarity below the threshold and sort by similarity, taking the top 5\n",
    "    top_matches = df_clip[df_clip[\"similarity\"] > threshold].sort_values(\"similarity\", ascending=False).head(5)\n",
    "\n",
    "    # For each top match, append to results\n",
    "    for rank, (_, row) in enumerate(top_matches.iterrows(), start=1):\n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"rank\": rank,\n",
    "            \"video_id\": row[\"video_id\"],\n",
    "            \"caption\": row[\"caption\"],\n",
    "            \"url\": row[\"url\"],\n",
    "            \"start\": row[\"start time\"],\n",
    "            \"end\": row[\"end time\"],\n",
    "            \"similarity\": row[\"similarity\"]\n",
    "        })\n",
    "\n",
    "# Save to CSV for manual annotation\n",
    "df_results = pd.DataFrame(results)\n",
    "if not os.path.exists(\"clip_bplus_results.csv\"):\n",
    "    results_df.to_csv(\"clip_bplus_results.csv\", index=False)\n",
    "    print(\"Results saved to clip_bplus_results.csv\")\n",
    "else:\n",
    "    print(\"File already exists. No save performed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5 per query:\n",
      "- a chef chopping vegetables in a kitchen...: 1.000\n",
      "- a crowded city street at night with neon signs...: 0.968\n",
      "- a firefighter rescuing a person from a burning bui...: 0.967\n",
      "- a golden retriever sitting on a grassy field...: 0.877\n",
      "- a peaceful beach with palm trees and waves crashin...: 1.000\n",
      "- a person jogging through a park in the morning...: 1.000\n",
      "- a person near luxury cars in cloudy weather speaki...: 1.000\n",
      "- a red sports car in front of a building...: 1.000\n",
      "- a snowy mountain with a clear blue sky...: 0.500\n",
      "- a surfer riding a big wave...: 1.000\n",
      "\n",
      "Mean NDCG@5 across all queries: 0.931\n"
     ]
    }
   ],
   "source": [
    "# Reload the results after manual annotation\n",
    "df = pd.read_csv(\"clip_bplus_results.csv\")\n",
    "\n",
    "# Convert the relevance column to numeric, handling errors and filling NaN with 0\n",
    "df[\"relevance\"] = pd.to_numeric(df[\"relevance\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# Function to calculate DCG\n",
    "def dcg(scores):\n",
    "    return sum(score / np.log2(idx + 2) for idx, score in enumerate(scores))\n",
    "\n",
    "# Dictionary to store NDCG scores\n",
    "ndcg_scores = {}\n",
    "\n",
    "# Calculate NDCG for each query\n",
    "for query, group in df.groupby(\"query\"):\n",
    "    # Sort by predicted rank \n",
    "    top_k = group.sort_values(\"rank\").head(5)\n",
    "    \n",
    "    # Calculate DCG for the ranking\n",
    "    relevance = top_k[\"relevance\"].tolist()\n",
    "    actual_dcg = dcg(relevance)\n",
    "    \n",
    "    # Ideal DCG (perfect ranking of same scores)\n",
    "    ideal_relevance = sorted(relevance, reverse=True)\n",
    "    ideal_dcg = dcg(ideal_relevance)\n",
    "    \n",
    "    # Calculate NDCG\n",
    "    ndcg = actual_dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "    ndcg_scores[query] = ndcg\n",
    "\n",
    "# Print per-query and average NDCG@5\n",
    "print(\"NDCG@5 per query:\")\n",
    "for query, score in ndcg_scores.items():\n",
    "    print(f\"- {query[:50]}...: {score:.3f}\")\n",
    "\n",
    "mean_ndcg = np.mean(list(ndcg_scores.values()))\n",
    "print(f\"\\nMean NDCG@5 across all queries: {mean_ndcg:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
