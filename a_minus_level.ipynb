{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_exists_youtube(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        time.sleep(1)  # Be polite to the server\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            return False\n",
    "\n",
    "        html = response.text.lower()\n",
    "        unavailable_phrases = [\n",
    "            \"video is not available\",\n",
    "            \"video unavailable\",\n",
    "            \"this video is private\",\n",
    "            \"this video has been removed\",\n",
    "            \"this video is no longer available\"\n",
    "        ]\n",
    "\n",
    "        for phrase in unavailable_phrases:\n",
    "            if phrase in html:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking video {url}: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MSR-VTT and remove duplicates\n",
    "df_raw = pd.read_parquet(\"train-00000-of-00001-60e50ff5fbbd1bb5.parquet\")\n",
    "df_unique = df_raw.drop_duplicates(subset=[\"video_id\"])\n",
    "\n",
    "# Check availability of first 550 URLs\n",
    "urls = df_unique[\"url\"].tolist()[:550]\n",
    "valid_urls = [url for url in urls if video_exists_youtube(url)]\n",
    "\n",
    "# Filter to only valid videos\n",
    "df_valid = df_unique[df_unique[\"url\"].isin(valid_urls)]\n",
    "\n",
    "# Sample 400 from the valid set\n",
    "sampled_video_ids = df_valid.sample(n=400, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_video_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original_sample = pd.read_csv(\"sampled_data_100_videos.csv\")\n",
    "\n",
    "sample_1k = pd.concat([df_original_sample, sampled_video_ids], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare metadata\n",
    "df_raw = pd.read_parquet(\"train-00000-of-00001-60e50ff5fbbd1bb5.parquet\")\n",
    "df_unique = df_raw.drop_duplicates(subset=[\"video_id\"]).copy()\n",
    "df_unique[\"image_path\"] = df_unique[\"video_id\"].apply(lambda vid: f\"images/{vid}.jpg\")\n",
    "df_unique = df_unique[df_unique[\"image_path\"].apply(lambda p: Path(p).exists())].reset_index(drop=True)\n",
    "\n",
    "# Load CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Initialize image embeddings and valid video IDs\n",
    "clip_embeddings = []\n",
    "valid_video_ids = []\n",
    "\n",
    "# for each image, preprocess and encode\n",
    "for _, row in df_unique.iterrows():\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        image = preprocess(Image.open(row[\"image_path\"])).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            # Encode the image\n",
    "            emb = model.encode_image(image).cpu().numpy()[0]\n",
    "\n",
    "        # Store the embedding and video ID\n",
    "        clip_embeddings.append(emb)\n",
    "        valid_video_ids.append(row[\"video_id\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle errors by skipping the video\n",
    "        print(f\"Skipping {row['video_id']}: {e}\")\n",
    "\n",
    "# Create DataFrame for valid videos\n",
    "df_clip = df_unique[df_unique[\"video_id\"].isin(valid_video_ids)].reset_index(drop=True)\n",
    "clip_embeddings = np.array(clip_embeddings)\n",
    "\n",
    "# Define text queries\n",
    "queries = [\n",
    "    \"a snowy mountain with a clear blue sky\",\n",
    "    \"a crowded city street at night with neon signs\",\n",
    "    \"a peaceful beach with palm trees and waves crashing\",\n",
    "    \"a person jogging through a park in the morning\",\n",
    "    \"a chef chopping vegetables in a kitchen\",\n",
    "    \"a surfer riding a big wave\",\n",
    "    \"a red sports car in front of a building\",\n",
    "    \"a golden retriever sitting on a grassy field\",\n",
    "    \"a firefighter rescuing a person from a burning building at night\",\n",
    "    \"a person near luxury cars in cloudy weather speaking to someone\"\n",
    "]\n",
    "\n",
    "# Encode text queries\n",
    "with torch.no_grad():\n",
    "    tokenized = clip.tokenize(queries).to(device)\n",
    "    query_embeddings = model.encode_text(tokenized).cpu().numpy()\n",
    "\n",
    "# Compute cosine similarity between query and image embeddings\n",
    "similarities = cosine_similarity(query_embeddings, clip_embeddings)\n",
    "\n",
    "# Initialize results list\n",
    "results = []\n",
    "\n",
    "# For each query, find the top 5 most similar videos\n",
    "for i, query in enumerate(queries):\n",
    "    # Get the similarity scores for the current query\n",
    "    scores = similarities[i]\n",
    "\n",
    "    # Store the similarity scores in the dataframe\n",
    "    df_clip[\"similarity\"] = scores\n",
    "\n",
    "    # sort by similarity and get the top 5\n",
    "    top5 = df_clip.sort_values(\"similarity\", ascending=False).head(5)\n",
    "\n",
    "    # For each of the top 5, create a result entry\n",
    "    for rank, (_, row) in enumerate(top5.iterrows(), start=1):\n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"rank\": rank,\n",
    "            \"video_id\": row[\"video_id\"],\n",
    "            \"caption\": row[\"caption\"],\n",
    "            \"url\": row[\"url\"],\n",
    "            \"start\": row[\"start time\"],\n",
    "            \"end\": row[\"end time\"],\n",
    "            \"similarity\": row[\"similarity\"]\n",
    "        })\n",
    "\n",
    "# Save to CSV for manual annotation\n",
    "df_results = pd.DataFrame(results)\n",
    "if not os.path.exists(\"clip_a_minus_results.csv\"):\n",
    "    results_df.to_csv(\"clip_a_minus_results.csv\", index=False)\n",
    "    print(\"Results saved to clip_a_minus_results.csv\")\n",
    "else:\n",
    "    print(\"File already exists. No save performed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5 per query:\n",
      "- a chef chopping vegetables in a kitchen...: 0.907\n",
      "- a crowded city street at night with neon signs...: 1.000\n",
      "- a firefighter rescuing a person from a burning bui...: 1.000\n",
      "- a golden retriever sitting on a grassy field...: 0.950\n",
      "- a peaceful beach with palm trees and waves crashin...: 0.776\n",
      "- a person jogging through a park in the morning...: 0.983\n",
      "- a person near luxury cars in cloudy weather speaki...: 0.896\n",
      "- a red sports car in front of a building...: 0.956\n",
      "- a snowy mountain with a clear blue sky...: 0.969\n",
      "- a surfer riding a big wave...: 1.000\n",
      "\n",
      "Mean NDCG@5 across all queries: 0.944\n"
     ]
    }
   ],
   "source": [
    "# Reload the results after manual annotation\n",
    "df = pd.read_csv(\"clip_a_minus_results.csv\")\n",
    "\n",
    "# Convert the relevance column to numeric, handling errors and filling NaN with 0\n",
    "df[\"relevance\"] = pd.to_numeric(df[\"relevance\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# Function to calculate DCG\n",
    "def dcg(scores):\n",
    "    return sum(score / np.log2(idx + 2) for idx, score in enumerate(scores))\n",
    "\n",
    "# Dictionary to store NDCG scores\n",
    "ndcg_scores = {}\n",
    "\n",
    "# Calculate NDCG for each query\n",
    "for query, group in df.groupby(\"query\"):\n",
    "    # Sort by predicted rank \n",
    "    top_k = group.sort_values(\"rank\").head(5)\n",
    "    \n",
    "    # Calculate DCG for the ranking\n",
    "    relevance = top_k[\"relevance\"].tolist()\n",
    "    actual_dcg = dcg(relevance)\n",
    "    \n",
    "    # Ideal DCG (perfect ranking of same scores)\n",
    "    ideal_relevance = sorted(relevance, reverse=True)\n",
    "    ideal_dcg = dcg(ideal_relevance)\n",
    "    \n",
    "    # Calculate NDCG\n",
    "    ndcg = actual_dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "    ndcg_scores[query] = ndcg\n",
    "\n",
    "# Print per-query and average NDCG@5\n",
    "print(\"NDCG@5 per query:\")\n",
    "for query, score in ndcg_scores.items():\n",
    "    print(f\"- {query[:50]}...: {score:.3f}\")\n",
    "\n",
    "mean_ndcg = np.mean(list(ndcg_scores.values()))\n",
    "print(f\"\\nMean NDCG@5 across all queries: {mean_ndcg:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
